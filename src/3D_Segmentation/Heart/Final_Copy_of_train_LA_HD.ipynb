{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Copy of train_LA_HD.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0eO-ny7tPHb"
      },
      "source": [
        "## Set up env"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt1xZ4Eds-dw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acaf395c-5ca7-4b44-94ca-fd323e292a1e"
      },
      "source": [
        "%pip install --user torch==1.8.1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okBmyX3kuE-6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f13b542-1338-427b-dbea-f319b26eef4f"
      },
      "source": [
        "!pip install monai"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting monai\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/75/73116b5fe93af8ea2bc69cbfded492d76e9423447b2a63af1171ff0740fe/monai-0.5.3-202106011449-py3-none-any.whl (497kB)\n",
            "\r\u001b[K     |▋                               | 10kB 20.2MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 27.6MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 22.7MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 17.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 8.9MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 9.2MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 9.3MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 10.3MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 10.7MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 112kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 122kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 133kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 143kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 225kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 235kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 245kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 256kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 266kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 276kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 286kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 337kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 348kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 368kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 378kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 399kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▍     | 409kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 430kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 440kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 450kB 8.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 460kB 8.6MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 471kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 481kB 8.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 491kB 8.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from monai) (1.19.5)\n",
            "Requirement already satisfied: torch>=1.5 in /usr/local/lib/python3.7/dist-packages (from monai) (1.8.1+cu101)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.5->monai) (3.7.4.3)\n",
            "Installing collected packages: monai\n",
            "Successfully installed monai-0.5.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtIs4_D-tCXv"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import h5py\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from monai.metrics import compute_meandice\n",
        "\n",
        "from scipy.ndimage import distance_transform_edt as distance\n",
        "from monai.transforms import (\n",
        "    AsDiscrete,\n",
        "    AddChanneld,\n",
        "    Compose,\n",
        "    CropForegroundd,\n",
        "    LoadImaged,\n",
        "    Orientationd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    ScaleIntensityRanged,\n",
        "    Spacingd,\n",
        "    ToTensord,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8VEUradtF85"
      },
      "source": [
        "import monai\n",
        "from monai.utils import first, set_determinism\n",
        "from monai.transforms import (\n",
        "    AsDiscrete,\n",
        "    AddChanneld,\n",
        "    Compose,\n",
        "    RandSpatialCropd,\n",
        "    CropForegroundd,\n",
        "    CenterSpatialCropd,\n",
        "    NormalizeIntensityd,\n",
        "    LoadImaged,\n",
        "    Orientationd,\n",
        "    RandCropByPosNegLabeld,\n",
        "    ScaleIntensityRanged,\n",
        "    Spacingd,\n",
        "    ToTensord,\n",
        ")\n",
        "from monai.networks.nets import UNet\n",
        "from monai.networks.layers import Norm\n",
        "from monai.metrics import compute_meandice\n",
        "from monai.losses import DiceLoss\n",
        "from monai.inferers import sliding_window_inference\n",
        "from monai.data import CacheDataset, DataLoader, Dataset\n",
        "from monai.config import print_config\n",
        "from monai.apps import download_and_extract\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import tempfile\n",
        "import shutil\n",
        "import os\n",
        "import glob\n",
        "from tqdm import tqdm_gui"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muawX563toW-"
      },
      "source": [
        "## Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLzPH8dMtMn-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b407ac88-f2b2-4ac1-bfc1-37347f17b7b6"
      },
      "source": [
        "directory = os.environ.get(\"MONAI_DATA_DIRECTORY\")\n",
        "root_dir = tempfile.mkdtemp() if directory is None else directory\n",
        "print(root_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/tmp/tmpvay3q8uv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0qjxHww0tWhx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67302db-e50d-412a-e755-44f2c3f81761"
      },
      "source": [
        "resource = \"https://msd-for-monai.s3-us-west-2.amazonaws.com/Task02_Heart.tar\"\n",
        "\n",
        "\n",
        "compressed_file = os.path.join(root_dir, \"Task02_Heart.tar\")\n",
        "data_dir = os.path.join(root_dir, \"Task02_Heart\")\n",
        "if not os.path.exists(data_dir):\n",
        "    download_and_extract(resource, compressed_file, root_dir)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/monai/apps/utils.py:158: UserWarning: tqdm is not installed, will not show the downloading progress bar.\n",
            "  warnings.warn(\"tqdm is not installed, will not show the downloading progress bar.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "downloaded file: /tmp/tmpt0rivzrf/Task02_Heart.tar.\n",
            "Expected md5 is None, skip md5 check for file /tmp/tmpt0rivzrf/Task02_Heart.tar.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-ODGPFJuNlt"
      },
      "source": [
        "## Set up datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENDQPjq5tsP0"
      },
      "source": [
        "train_images = sorted(\n",
        "    glob.glob(os.path.join(data_dir, \"imagesTr\", \"*.nii.gz\")))\n",
        "train_labels = sorted(\n",
        "    glob.glob(os.path.join(data_dir, \"labelsTr\", \"*.nii.gz\")))\n",
        "data_dicts = [\n",
        "    {\"image\": image_name, \"label\": label_name}\n",
        "    for image_name, label_name in zip(train_images, train_labels)\n",
        "]\n",
        "train_files, val_files = data_dicts[:-9], data_dicts[-9:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nondHmoxuPMS"
      },
      "source": [
        "set_determinism(seed=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phwx6SS8hpR0"
      },
      "source": [
        "image_size = (96, 96, 96)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ChBwmowiue8g"
      },
      "source": [
        "train_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        AddChanneld(keys=[\"image\", \"label\"]),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"], a_min=-57, a_max=164,\n",
        "            b_min=0.0, b_max=1.0, clip=True),\n",
        "        CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=image_size),\n",
        "        ToTensord(keys=[\"image\", \"label\"]),\n",
        "     ]\n",
        " )\n",
        "val_transforms = Compose(\n",
        "    [\n",
        "        LoadImaged(keys=[\"image\", \"label\"]),\n",
        "        AddChanneld(keys=[\"image\", \"label\"]),\n",
        "        ScaleIntensityRanged(\n",
        "            keys=[\"image\"], a_min=-57, a_max=164,\n",
        "            b_min=0.0, b_max=1.0, clip=True),\n",
        "        CenterSpatialCropd(keys=[\"image\", \"label\"], roi_size=image_size),\n",
        "        ToTensord(keys=[\"image\", \"label\"]),\n",
        "    ]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yi3dTj0fviLB"
      },
      "source": [
        "## Visualize dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfAJ9tLHvMWw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "outputId": "0eae83c6-2f2c-44f1-e178-7591e24fff20"
      },
      "source": [
        "check_ds = Dataset(data=train_files, transform=train_transforms)\n",
        "check_loader = DataLoader(check_ds, batch_size=1)\n",
        "check_data = first(check_loader)\n",
        "image, label = (check_data[\"image\"][0][0], check_data[\"label\"][0][0])\n",
        "print(f\"image shape: {image.shape}, label shape: {label.shape}\")\n",
        "# plot the slice [:, :, 80]\n",
        "plt.figure(\"check\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"image\")\n",
        "plt.imshow(image[:, :, 40], cmap=\"gray\")\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"label\")\n",
        "plt.imshow(label[:, :, 60])\n",
        "plt.show()\n",
        "print(check_data['label'].shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "image shape: torch.Size([96, 96, 96]), label shape: torch.Size([96, 96, 96])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 96, 96, 96])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hij2BTSvllz"
      },
      "source": [
        "## Set up loss functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGMCyCQpvf3N"
      },
      "source": [
        "def dice_loss(score, target):\n",
        "    target = target.float()\n",
        "    smooth = 1e-5\n",
        "    intersect = torch.sum(score * target)\n",
        "    y_sum = torch.sum(target * target)\n",
        "    z_sum = torch.sum(score * score)\n",
        "    loss = (2 * intersect + smooth) / (z_sum + y_sum + smooth)\n",
        "    loss = 1 - loss\n",
        "    return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G5Wrh8xGvq3N"
      },
      "source": [
        "def compute_dtm(img_gt, out_shape):\n",
        "    \"\"\"\n",
        "    compute the distance transform map of foreground in binary mask\n",
        "    input: segmentation, shape = (batch_size, x, y, z)\n",
        "    output: the foreground Distance Map (SDM) \n",
        "    dtm(x) = 0; x in segmentation boundary\n",
        "             inf|x-y|; x in segmentation\n",
        "    \"\"\"\n",
        "\n",
        "    fg_dtm = np.zeros(out_shape)\n",
        "\n",
        "    for b in range(out_shape[0]): # batch size\n",
        "        for c in range(1, out_shape[1]):\n",
        "            posmask = img_gt[b].astype(np.bool)\n",
        "            if posmask.any():\n",
        "                posdis = distance(posmask)\n",
        "                fg_dtm[b][c] = posdis\n",
        "\n",
        "    return fg_dtm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02AJQmHLvsaq"
      },
      "source": [
        "def hd_loss(seg_soft, gt, seg_dtm, gt_dtm):\n",
        "    \"\"\"\n",
        "    compute huasdorff distance loss for binary segmentation\n",
        "    input: seg_soft: softmax results,  shape=(b,2,x,y,z)\n",
        "           gt: ground truth, shape=(b,x,y,z)\n",
        "           seg_dtm: segmentation distance transform map; shape=(b,2,x,y,z)\n",
        "           gt_dtm: ground truth distance transform map; shape=(b,2,x,y,z)\n",
        "    output: boundary_loss; sclar\n",
        "    \"\"\"\n",
        "\n",
        "    delta_s = (seg_soft[:,1,...] - gt.float()[:,0,...]) ** 2\n",
        "    s_dtm = seg_dtm[:,1,...] ** 2\n",
        "    g_dtm = gt_dtm[:,1,...] ** 2\n",
        "    dtm = s_dtm + g_dtm\n",
        "    multipled = torch.einsum('bxyz, bxyz->bxyz', delta_s, dtm)\n",
        "    hd_loss = multipled.mean()\n",
        "\n",
        "    return hd_loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wh-cxlBC9LKR"
      },
      "source": [
        "## Set up dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HwxiG_b9NqQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b136ed06-871f-41c7-8f34-da6f303a4c53"
      },
      "source": [
        "train_ds = CacheDataset(\n",
        "    data=train_files, transform=train_transforms,\n",
        "     cache_rate=1.0, num_workers=4)\n",
        "#train_ds = monai.data.Dataset(data=train_files, transform=train_transforms)\n",
        "\n",
        "# use batch_size=2 to load images and use RandCropByPosNegLabeld\n",
        "# to generate 2 x 4 images for network training\n",
        "train_loader = DataLoader(train_ds, batch_size=1, shuffle=True, num_workers=4)\n",
        "\n",
        "val_ds = CacheDataset(\n",
        "  data=val_files, transform=val_transforms, cache_rate=1.0, num_workers=4)\n",
        "#val_ds = Dataset(data=val_files, transform=val_transforms)\n",
        "val_loader = DataLoader(val_ds, batch_size=1, num_workers=4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/monai/data/dataset.py:540: UserWarning: tqdm is not installed, will not show the caching progress bar.\n",
            "  warnings.warn(\"tqdm is not installed, will not show the caching progress bar.\")\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHXRbm85w_am"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ylz9xowhvuPu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f1b70ce-3967-4052-e209-f9c47b0e0b9b"
      },
      "source": [
        "device = torch.device(\"cuda:0\")\n",
        "net = monai.networks.nets.BasicUNet().to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "BasicUNet features: (32, 32, 64, 128, 256, 32).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t8b5Mg4KxgJ2"
      },
      "source": [
        "base_lr = 0.001\n",
        "max_iterations = 20000"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C5dGgmFsxLE4"
      },
      "source": [
        "optimizer = torch.optim.Adam(net.parameters(), lr=base_lr, momentum=0.9, weight_decay=0.0001)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "suLrsppixYOD"
      },
      "source": [
        "iter_num = 0\n",
        "alpha = 1.0\n",
        "\n",
        "lr_ = base_lr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UjfO1oXc3BlY"
      },
      "source": [
        "max_epochs = 60\n",
        "val_interval = 2\n",
        "best_metric = -1\n",
        "best_metric_epoch = -1\n",
        "epoch_loss_values = []\n",
        "val_epoch_loss = []\n",
        "metric_values = []\n",
        "time_list_epoch = []\n",
        "time_list_batch = []\n",
        "metric_count = 0\n",
        "metric_sum = 0.0\n",
        "new_loss = 0\n",
        "post_pred = AsDiscrete(argmax=True, to_onehot=True, n_classes=2)\n",
        "post_label = AsDiscrete(to_onehot=True, n_classes=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "43kJlL73avPP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20737a4d-5034-4049-eadf-2b8664f610da"
      },
      "source": [
        "time.time()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1623274655.5590858"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TMWSzTamxr8r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "825f5487-6018-46d2-9a6a-e049ca05c306"
      },
      "source": [
        "for epoch_num in range(max_epochs):\n",
        "    time_list_epoch.append(time.time())\n",
        "    print(\"-\" * 10)\n",
        "    print(f\"epoch {epoch_num + 1}/{max_epochs}\")\n",
        "    net.train()\n",
        "    epoch_loss = 0\n",
        "    step = 0\n",
        "    for i_batch, sampled_batch in enumerate(train_loader):\n",
        "        time_list_batch.append(time.time())\n",
        "        step +=1\n",
        "        # print('fetch data cost {}'.format(time2-time1))\n",
        "        # volume_batch.shape=(b,1,x,y,z) label_patch.shape=(b,x,y,z)\n",
        "        volume_batch, label_batch = sampled_batch['image'].cuda(), sampled_batch['label'].cuda()\n",
        "        outputs = net(volume_batch)\n",
        "        outputs, label_batch = outputs.type(torch.Tensor), label_batch.type(torch.Tensor)\n",
        "\n",
        "        loss_seg = 0\n",
        "        # for i in range(outputs.size()[2]):\n",
        "        #     # print(outputs[:, :, i].shape, \"\\n\", label_batch[:, i].shape)\n",
        "        #     loss_seg += F.cross_entropy(outputs[:, :, i], label_batch[:, i])\n",
        "\n",
        "        outputs_soft = F.softmax(outputs, dim=1)\n",
        "        loss_seg_dice = dice_loss(outputs_soft[:, 1, :, :, :], label_batch == 1)\n",
        "        # compute distance maps and hd loss\n",
        "        with torch.no_grad():\n",
        "            # defalut using compute_dtm; however, compute_dtm01 is also worth to try;\n",
        "            gt_dtm_npy = compute_dtm(label_batch.cpu().numpy(), outputs_soft.shape)\n",
        "            gt_dtm = torch.from_numpy(gt_dtm_npy).float().cuda(outputs_soft.device.index)\n",
        "            seg_dtm_npy = compute_dtm(outputs_soft[:, 1, :, :, :].cpu().numpy()>0.5, outputs_soft.shape)\n",
        "            seg_dtm = torch.from_numpy(seg_dtm_npy).float().cuda(outputs_soft.device.index)\n",
        "\n",
        "            \n",
        "\n",
        "        loss_hd = hd_loss(outputs_soft.cpu(), label_batch.cpu(), seg_dtm.cpu(), gt_dtm.cpu())\n",
        "        loss = alpha*(loss_seg+loss_seg_dice) + (1 - alpha) * loss_hd\n",
        "        y_pred = post_pred(outputs)\n",
        "        y = post_label(label_batch)\n",
        "\n",
        "        accu = compute_meandice(\n",
        "                    y_pred=y_pred,\n",
        "                    y=y,\n",
        "                    include_background=False,\n",
        "                )\n",
        "        acc = accu.sum().item()/len(accu)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        epoch_loss += loss.item()\n",
        "        print(\n",
        "            f\"{step}/{len(train_ds) // train_loader.batch_size}, \"\n",
        "            f\"train_loss: {loss:.4f},\"\n",
        "            f\"acc: {acc:.4f}\")\n",
        "\n",
        "\n",
        "        iter_num = iter_num + 1\n",
        "\n",
        "        ## change lr\n",
        "        if iter_num % 2500 == 0:\n",
        "            lr_ = base_lr * 0.1 ** (iter_num // 2500)\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr_\n",
        "        if iter_num % 1000 == 0:\n",
        "            save_mode_path = os.path.join(snapshot_path, 'iter_' + str(iter_num) + '.pth')\n",
        "            torch.save(net.state_dict(), save_mode_path)\n",
        "            logging.info(\"save model to {}\".format(save_mode_path))\n",
        "\n",
        "        if iter_num > max_iterations:\n",
        "            break\n",
        "        time1 = time.time()\n",
        "    epoch_loss /= step\n",
        "    epoch_loss_values.append(epoch_loss)\n",
        "    print(f\"epoch {epoch_num + 1} average loss: {epoch_loss:.4f}\")\n",
        "    alpha -= 0.001\n",
        "    if alpha <= 0.001:\n",
        "        alpha = 0.001\n",
        "\n",
        "\n",
        "    if (epoch_num + 1) % val_interval == 0:\n",
        "        new_loss = 0\n",
        "        net.eval()\n",
        "        val_step = 0\n",
        "        with torch.no_grad():\n",
        "            metric_sum = 0.0\n",
        "            metric_count = 0\n",
        "            val_step +=1\n",
        "            for val_data in val_loader:\n",
        "                val_inputs, val_labels = (\n",
        "                    val_data[\"image\"].cuda(),\n",
        "                    val_data[\"label\"].cuda()\n",
        "                )\n",
        "                roi_size = (96,96,96)\n",
        "                sw_batch_size = 4\n",
        "                val_outputs = sliding_window_inference(\n",
        "                    val_inputs, roi_size, sw_batch_size, net)\n",
        "                val_outputs, val_labels = val_outputs.type(torch.Tensor), val_labels.type(torch.Tensor)\n",
        "                loss_seg = 0\n",
        "                outputs_soft = F.softmax(val_outputs, dim=1)\n",
        "                loss_seg_dice = dice_loss(outputs_soft[:, 1, :, :, :], val_labels == 1)\n",
        "                # compute distance maps and hd loss\n",
        "                with torch.no_grad():\n",
        "                # defalut using compute_dtm; however, compute_dtm01 is also worth to try;\n",
        "                    gt_dtm_npy = compute_dtm(val_labels.cpu().numpy(), outputs_soft.shape)\n",
        "                    gt_dtm = torch.from_numpy(gt_dtm_npy).float().cuda(outputs_soft.device.index)\n",
        "                    seg_dtm_npy = compute_dtm(outputs_soft[:, 1, :, :, :].cpu().numpy()>0.5, outputs_soft.shape)\n",
        "                    seg_dtm = torch.from_numpy(seg_dtm_npy).float().cuda(outputs_soft.device.index)\n",
        "\n",
        "            \n",
        "\n",
        "                loss_hd = hd_loss(outputs_soft.cpu(), val_labels.cpu(), seg_dtm.cpu(), gt_dtm.cpu())\n",
        "                val_loss = alpha*(loss_seg+loss_seg_dice) + (1 - alpha) * loss_hd\n",
        "                new_loss+= val_loss.item()\n",
        "\n",
        "                val_outputs = post_pred(val_outputs)\n",
        "                val_labels = post_label(val_labels)\n",
        "                value = compute_meandice(\n",
        "                    y_pred=val_outputs,\n",
        "                    y=val_labels,\n",
        "                    include_background=False,\n",
        "                )\n",
        "                metric_count += len(value)\n",
        "                metric_sum += value.sum().item()\n",
        "            metric = metric_sum / metric_count\n",
        "            metric_values.append(metric)\n",
        "            new_loss /= val_step\n",
        "            val_epoch_loss.append(new_loss)\n",
        "            if metric > best_metric:\n",
        "                best_metric = metric\n",
        "                best_metric_epoch = epoch_num + 1\n",
        "                torch.save(net.state_dict(), os.path.join(\n",
        "                    root_dir, \"best_metric_model.pth\"))\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch_num + 1} current mean dice: {metric:.4f} current Val Loss: {val_loss.item():.4f}\"\n",
        "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
        "                f\"at epoch: {best_metric_epoch}\"\n",
        "            )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------\n",
            "epoch 1/60\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1/11, train_loss: 0.8775,acc: 0.0011\n",
            "2/11, train_loss: 0.8534,acc: 0.0054\n",
            "3/11, train_loss: 0.8221,acc: 0.0068\n",
            "4/11, train_loss: 0.8484,acc: 0.0024\n",
            "5/11, train_loss: 0.8661,acc: 0.0198\n",
            "6/11, train_loss: 0.8018,acc: 0.0376\n",
            "7/11, train_loss: 0.7968,acc: 0.1355\n",
            "8/11, train_loss: 0.7887,acc: 0.1668\n",
            "9/11, train_loss: 0.8409,acc: 0.1230\n",
            "10/11, train_loss: 0.7511,acc: 0.2021\n",
            "11/11, train_loss: 0.7927,acc: 0.1642\n",
            "epoch 1 average loss: 0.8218\n",
            "----------\n",
            "epoch 2/60\n",
            "1/11, train_loss: 0.8540,acc: 0.1129\n",
            "2/11, train_loss: 0.8118,acc: 0.1548\n",
            "3/11, train_loss: 0.8274,acc: 0.1368\n",
            "4/11, train_loss: 0.7436,acc: 0.2102\n",
            "5/11, train_loss: 0.7796,acc: 0.1806\n",
            "6/11, train_loss: 0.7753,acc: 0.1877\n",
            "7/11, train_loss: 0.8470,acc: 0.1252\n",
            "8/11, train_loss: 0.7898,acc: 0.1768\n",
            "9/11, train_loss: 0.8350,acc: 0.1326\n",
            "10/11, train_loss: 0.7920,acc: 0.1708\n",
            "11/11, train_loss: 0.7796,acc: 0.1869\n",
            "epoch 2 average loss: 0.8032\n",
            "saved new best metric model\n",
            "current epoch: 2 current mean dice: 0.1377 current Val Loss: 0.8246\n",
            "best mean dice: 0.1377 at epoch: 2\n",
            "----------\n",
            "epoch 3/60\n",
            "1/11, train_loss: 0.7444,acc: 0.2190\n",
            "2/11, train_loss: 0.7870,acc: 0.1935\n",
            "3/11, train_loss: 0.8382,acc: 0.1447\n",
            "4/11, train_loss: 0.8431,acc: 0.1362\n",
            "5/11, train_loss: 0.7955,acc: 0.1836\n",
            "6/11, train_loss: 0.8593,acc: 0.1230\n",
            "7/11, train_loss: 0.8032,acc: 0.1748\n",
            "8/11, train_loss: 0.8117,acc: 0.1709\n",
            "9/11, train_loss: 0.8529,acc: 0.1323\n",
            "10/11, train_loss: 0.7903,acc: 0.1939\n",
            "11/11, train_loss: 0.7806,acc: 0.1922\n",
            "epoch 3 average loss: 0.8096\n",
            "----------\n",
            "epoch 4/60\n",
            "1/11, train_loss: 0.8446,acc: 0.1486\n",
            "2/11, train_loss: 0.8123,acc: 0.1771\n",
            "3/11, train_loss: 0.8167,acc: 0.1761\n",
            "4/11, train_loss: 0.7919,acc: 0.1924\n",
            "5/11, train_loss: 0.8608,acc: 0.1262\n",
            "6/11, train_loss: 0.7961,acc: 0.1996\n",
            "7/11, train_loss: 0.7831,acc: 0.1977\n",
            "8/11, train_loss: 0.8382,acc: 0.1430\n",
            "9/11, train_loss: 0.8508,acc: 0.1396\n",
            "10/11, train_loss: 0.7333,acc: 0.2376\n",
            "11/11, train_loss: 0.7736,acc: 0.2101\n",
            "epoch 4 average loss: 0.8092\n",
            "saved new best metric model\n",
            "current epoch: 4 current mean dice: 0.1505 current Val Loss: 0.8181\n",
            "best mean dice: 0.1505 at epoch: 4\n",
            "----------\n",
            "epoch 5/60\n",
            "1/11, train_loss: 0.8554,acc: 0.1417\n",
            "2/11, train_loss: 0.8073,acc: 0.1837\n",
            "3/11, train_loss: 0.8082,acc: 0.1861\n",
            "4/11, train_loss: 0.7349,acc: 0.2437\n",
            "5/11, train_loss: 0.8326,acc: 0.1569\n",
            "6/11, train_loss: 0.8341,acc: 0.1498\n",
            "7/11, train_loss: 0.7896,acc: 0.2098\n",
            "8/11, train_loss: 0.7797,acc: 0.2077\n",
            "9/11, train_loss: 0.7692,acc: 0.2203\n",
            "10/11, train_loss: 0.7723,acc: 0.2097\n",
            "11/11, train_loss: 0.8461,acc: 0.1358\n",
            "epoch 5 average loss: 0.8027\n",
            "----------\n",
            "epoch 6/60\n",
            "1/11, train_loss: 0.8022,acc: 0.1932\n",
            "2/11, train_loss: 0.8287,acc: 0.1568\n",
            "3/11, train_loss: 0.7768,acc: 0.2152\n",
            "4/11, train_loss: 0.8423,acc: 0.1539\n",
            "5/11, train_loss: 0.7229,acc: 0.2629\n",
            "6/11, train_loss: 0.7828,acc: 0.1985\n",
            "7/11, train_loss: 0.7594,acc: 0.2305\n",
            "8/11, train_loss: 0.7623,acc: 0.2187\n",
            "9/11, train_loss: 0.8083,acc: 0.1677\n",
            "10/11, train_loss: 0.8340,acc: 0.1413\n",
            "11/11, train_loss: 0.7635,acc: 0.2272\n",
            "epoch 6 average loss: 0.7894\n",
            "saved new best metric model\n",
            "current epoch: 6 current mean dice: 0.1685 current Val Loss: 0.7914\n",
            "best mean dice: 0.1685 at epoch: 6\n",
            "----------\n",
            "epoch 7/60\n",
            "1/11, train_loss: 0.7482,acc: 0.2049\n",
            "2/11, train_loss: 0.8302,acc: 0.1434\n",
            "3/11, train_loss: 0.7068,acc: 0.2813\n",
            "4/11, train_loss: 0.7818,acc: 0.2050\n",
            "5/11, train_loss: 0.7762,acc: 0.1726\n",
            "6/11, train_loss: 0.7322,acc: 0.2306\n",
            "7/11, train_loss: 0.7870,acc: 0.1794\n",
            "8/11, train_loss: 0.7210,acc: 0.2402\n",
            "9/11, train_loss: 0.7477,acc: 0.2365\n",
            "10/11, train_loss: 0.7187,acc: 0.2490\n",
            "11/11, train_loss: 0.8061,acc: 0.1705\n",
            "epoch 7 average loss: 0.7596\n",
            "----------\n",
            "epoch 8/60\n",
            "1/11, train_loss: 0.8075,acc: 0.1711\n",
            "2/11, train_loss: 0.7457,acc: 0.2395\n",
            "3/11, train_loss: 0.6815,acc: 0.2978\n",
            "4/11, train_loss: 0.7196,acc: 0.2379\n",
            "5/11, train_loss: 0.7667,acc: 0.1745\n",
            "6/11, train_loss: 0.7993,acc: 0.1503\n",
            "7/11, train_loss: 0.7667,acc: 0.2136\n",
            "8/11, train_loss: 0.7768,acc: 0.1918\n",
            "9/11, train_loss: 0.7080,acc: 0.2597\n",
            "10/11, train_loss: 0.7275,acc: 0.1994\n",
            "11/11, train_loss: 0.7072,acc: 0.2566\n",
            "epoch 8 average loss: 0.7460\n",
            "saved new best metric model\n",
            "current epoch: 8 current mean dice: 0.1818 current Val Loss: 0.7537\n",
            "best mean dice: 0.1818 at epoch: 8\n",
            "----------\n",
            "epoch 9/60\n",
            "1/11, train_loss: 0.7548,acc: 0.2191\n",
            "2/11, train_loss: 0.7262,acc: 0.2549\n",
            "3/11, train_loss: 0.7601,acc: 0.1713\n",
            "4/11, train_loss: 0.6698,acc: 0.3064\n",
            "5/11, train_loss: 0.7233,acc: 0.1879\n",
            "6/11, train_loss: 0.6972,acc: 0.2733\n",
            "7/11, train_loss: 0.7048,acc: 0.2498\n",
            "8/11, train_loss: 0.7681,acc: 0.1946\n",
            "9/11, train_loss: 0.7889,acc: 0.1529\n",
            "10/11, train_loss: 0.7764,acc: 0.1942\n",
            "11/11, train_loss: 0.6978,acc: 0.2544\n",
            "epoch 9 average loss: 0.7334\n",
            "----------\n",
            "epoch 10/60\n",
            "1/11, train_loss: 0.6627,acc: 0.3026\n",
            "2/11, train_loss: 0.6999,acc: 0.2482\n",
            "3/11, train_loss: 0.7069,acc: 0.2830\n",
            "4/11, train_loss: 0.7283,acc: 0.2375\n",
            "5/11, train_loss: 0.6937,acc: 0.2589\n",
            "6/11, train_loss: 0.7153,acc: 0.1801\n",
            "7/11, train_loss: 0.6862,acc: 0.2847\n",
            "8/11, train_loss: 0.7503,acc: 0.1662\n",
            "9/11, train_loss: 0.7682,acc: 0.2041\n",
            "10/11, train_loss: 0.7819,acc: 0.1585\n",
            "11/11, train_loss: 0.7574,acc: 0.2092\n",
            "epoch 10 average loss: 0.7228\n",
            "saved new best metric model\n",
            "current epoch: 10 current mean dice: 0.1939 current Val Loss: 0.7346\n",
            "best mean dice: 0.1939 at epoch: 10\n",
            "----------\n",
            "epoch 11/60\n",
            "1/11, train_loss: 0.7652,acc: 0.2069\n",
            "2/11, train_loss: 0.7553,acc: 0.2076\n",
            "3/11, train_loss: 0.6799,acc: 0.2809\n",
            "4/11, train_loss: 0.6940,acc: 0.3056\n",
            "5/11, train_loss: 0.6493,acc: 0.2934\n",
            "6/11, train_loss: 0.7076,acc: 0.1185\n",
            "7/11, train_loss: 0.6873,acc: 0.2398\n",
            "8/11, train_loss: 0.7431,acc: 0.1320\n",
            "9/11, train_loss: 0.7132,acc: 0.2524\n",
            "10/11, train_loss: 0.6804,acc: 0.2519\n",
            "11/11, train_loss: 0.7742,acc: 0.1573\n",
            "epoch 11 average loss: 0.7136\n",
            "----------\n",
            "epoch 12/60\n",
            "1/11, train_loss: 0.7731,acc: 0.1566\n",
            "2/11, train_loss: 0.7094,acc: 0.2506\n",
            "3/11, train_loss: 0.6696,acc: 0.2791\n",
            "4/11, train_loss: 0.6806,acc: 0.2277\n",
            "5/11, train_loss: 0.7005,acc: 0.0871\n",
            "6/11, train_loss: 0.7369,acc: 0.1113\n",
            "7/11, train_loss: 0.7417,acc: 0.1977\n",
            "8/11, train_loss: 0.7503,acc: 0.2073\n",
            "9/11, train_loss: 0.6350,acc: 0.2647\n",
            "10/11, train_loss: 0.6707,acc: 0.1916\n",
            "11/11, train_loss: 0.6750,acc: 0.2989\n",
            "epoch 12 average loss: 0.7039\n",
            "current epoch: 12 current mean dice: 0.1863 current Val Loss: 0.7141\n",
            "best mean dice: 0.1939 at epoch: 10\n",
            "----------\n",
            "epoch 13/60\n",
            "1/11, train_loss: 0.6735,acc: 0.3072\n",
            "2/11, train_loss: 0.6725,acc: 0.2154\n",
            "3/11, train_loss: 0.6935,acc: 0.0871\n",
            "4/11, train_loss: 0.7637,acc: 0.1628\n",
            "5/11, train_loss: 0.6269,acc: 0.3055\n",
            "6/11, train_loss: 0.6952,acc: 0.2712\n",
            "7/11, train_loss: 0.6625,acc: 0.2662\n",
            "8/11, train_loss: 0.6529,acc: 0.3139\n",
            "9/11, train_loss: 0.7296,acc: 0.2292\n",
            "10/11, train_loss: 0.7388,acc: 0.2260\n",
            "11/11, train_loss: 0.7254,acc: 0.1202\n",
            "epoch 13 average loss: 0.6940\n",
            "----------\n",
            "epoch 14/60\n",
            "1/11, train_loss: 0.7572,acc: 0.1652\n",
            "2/11, train_loss: 0.6467,acc: 0.2635\n",
            "3/11, train_loss: 0.6603,acc: 0.1853\n",
            "4/11, train_loss: 0.7323,acc: 0.2005\n",
            "5/11, train_loss: 0.6140,acc: 0.2581\n",
            "6/11, train_loss: 0.6830,acc: 0.2116\n",
            "7/11, train_loss: 0.6801,acc: 0.0849\n",
            "8/11, train_loss: 0.6485,acc: 0.2342\n",
            "9/11, train_loss: 0.6473,acc: 0.3805\n",
            "10/11, train_loss: 0.7171,acc: 0.1374\n",
            "11/11, train_loss: 0.7150,acc: 0.2469\n",
            "epoch 14 average loss: 0.6819\n",
            "saved new best metric model\n",
            "current epoch: 14 current mean dice: 0.2345 current Val Loss: 0.6887\n",
            "best mean dice: 0.2345 at epoch: 14\n",
            "----------\n",
            "epoch 15/60\n",
            "1/11, train_loss: 0.7485,acc: 0.1939\n",
            "2/11, train_loss: 0.6426,acc: 0.3907\n",
            "3/11, train_loss: 0.7232,acc: 0.2377\n",
            "4/11, train_loss: 0.6400,acc: 0.2850\n",
            "5/11, train_loss: 0.6713,acc: 0.1427\n",
            "6/11, train_loss: 0.5966,acc: 0.3444\n",
            "7/11, train_loss: 0.6254,acc: 0.3382\n",
            "8/11, train_loss: 0.6419,acc: 0.2722\n",
            "9/11, train_loss: 0.7086,acc: 0.1555\n",
            "10/11, train_loss: 0.6653,acc: 0.3104\n",
            "11/11, train_loss: 0.7023,acc: 0.2861\n",
            "epoch 15 average loss: 0.6696\n",
            "----------\n",
            "epoch 16/60\n",
            "1/11, train_loss: 0.7501,acc: 0.2085\n",
            "2/11, train_loss: 0.6369,acc: 0.3057\n",
            "3/11, train_loss: 0.6980,acc: 0.2913\n",
            "4/11, train_loss: 0.6260,acc: 0.3340\n",
            "5/11, train_loss: 0.6195,acc: 0.4193\n",
            "6/11, train_loss: 0.6591,acc: 0.2012\n",
            "7/11, train_loss: 0.6545,acc: 0.3195\n",
            "8/11, train_loss: 0.7109,acc: 0.2532\n",
            "9/11, train_loss: 0.7000,acc: 0.1743\n",
            "10/11, train_loss: 0.5830,acc: 0.4122\n",
            "11/11, train_loss: 0.6077,acc: 0.3990\n",
            "epoch 16 average loss: 0.6587\n",
            "saved new best metric model\n",
            "current epoch: 16 current mean dice: 0.2727 current Val Loss: 0.6729\n",
            "best mean dice: 0.2727 at epoch: 16\n",
            "----------\n",
            "epoch 17/60\n",
            "1/11, train_loss: 0.5877,acc: 0.4185\n",
            "2/11, train_loss: 0.6563,acc: 0.2711\n",
            "3/11, train_loss: 0.6572,acc: 0.3255\n",
            "4/11, train_loss: 0.6426,acc: 0.3662\n",
            "5/11, train_loss: 0.6392,acc: 0.3375\n",
            "6/11, train_loss: 0.7490,acc: 0.2268\n",
            "7/11, train_loss: 0.5989,acc: 0.4175\n",
            "8/11, train_loss: 0.5994,acc: 0.4458\n",
            "9/11, train_loss: 0.6922,acc: 0.1975\n",
            "10/11, train_loss: 0.6772,acc: 0.3387\n",
            "11/11, train_loss: 0.6888,acc: 0.2768\n",
            "epoch 17 average loss: 0.6535\n",
            "----------\n",
            "epoch 18/60\n",
            "1/11, train_loss: 0.6317,acc: 0.3234\n",
            "2/11, train_loss: 0.6871,acc: 0.1999\n",
            "3/11, train_loss: 0.6083,acc: 0.3624\n",
            "4/11, train_loss: 0.6949,acc: 0.2875\n",
            "5/11, train_loss: 0.5847,acc: 0.4515\n",
            "6/11, train_loss: 0.6758,acc: 0.3394\n",
            "7/11, train_loss: 0.5573,acc: 0.4697\n",
            "8/11, train_loss: 0.7237,acc: 0.2629\n",
            "9/11, train_loss: 0.6031,acc: 0.4233\n",
            "10/11, train_loss: 0.5763,acc: 0.4788\n",
            "11/11, train_loss: 0.6370,acc: 0.3429\n",
            "epoch 18 average loss: 0.6345\n",
            "saved new best metric model\n",
            "current epoch: 18 current mean dice: 0.3496 current Val Loss: 0.6299\n",
            "best mean dice: 0.3496 at epoch: 18\n",
            "----------\n",
            "epoch 19/60\n",
            "1/11, train_loss: 0.6758,acc: 0.3181\n",
            "2/11, train_loss: 0.6240,acc: 0.3547\n",
            "3/11, train_loss: 0.6953,acc: 0.2997\n",
            "4/11, train_loss: 0.6441,acc: 0.4011\n",
            "5/11, train_loss: 0.5517,acc: 0.4591\n",
            "6/11, train_loss: 0.5219,acc: 0.5166\n",
            "7/11, train_loss: 0.5950,acc: 0.4290\n",
            "8/11, train_loss: 0.5623,acc: 0.4627\n",
            "9/11, train_loss: 0.6142,acc: 0.4134\n",
            "10/11, train_loss: 0.6917,acc: 0.2788\n",
            "11/11, train_loss: 0.5814,acc: 0.4241\n",
            "epoch 19 average loss: 0.6143\n",
            "----------\n",
            "epoch 20/60\n",
            "1/11, train_loss: 0.5676,acc: 0.4644\n",
            "2/11, train_loss: 0.6566,acc: 0.2949\n",
            "3/11, train_loss: 0.6605,acc: 0.3481\n",
            "4/11, train_loss: 0.5443,acc: 0.4716\n",
            "5/11, train_loss: 0.4839,acc: 0.5636\n",
            "6/11, train_loss: 0.4945,acc: 0.5877\n",
            "7/11, train_loss: 0.6283,acc: 0.3688\n",
            "8/11, train_loss: 0.6210,acc: 0.3860\n",
            "9/11, train_loss: 0.5179,acc: 0.4903\n",
            "10/11, train_loss: 0.5595,acc: 0.4572\n",
            "11/11, train_loss: 0.6007,acc: 0.4126\n",
            "epoch 20 average loss: 0.5759\n",
            "saved new best metric model\n",
            "current epoch: 20 current mean dice: 0.5152 current Val Loss: 0.5380\n",
            "best mean dice: 0.5152 at epoch: 20\n",
            "----------\n",
            "epoch 21/60\n",
            "1/11, train_loss: 0.5311,acc: 0.5062\n",
            "2/11, train_loss: 0.6065,acc: 0.0866\n",
            "3/11, train_loss: 0.5746,acc: 0.4678\n",
            "4/11, train_loss: 0.4640,acc: 0.5576\n",
            "5/11, train_loss: 0.4328,acc: 0.6026\n",
            "6/11, train_loss: 0.5356,acc: 0.4717\n",
            "7/11, train_loss: 0.6135,acc: 0.3871\n",
            "8/11, train_loss: 0.6014,acc: 0.3933\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-7ca0a707943d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# defalut using compute_dtm; however, compute_dtm01 is also worth to try;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mgt_dtm_npy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_dtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_soft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mgt_dtm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt_dtm_npy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_soft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mseg_dtm_npy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_dtm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs_soft\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_soft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-6c0c4f4644db>\u001b[0m in \u001b[0;36mcompute_dtm\u001b[0;34m(img_gt, out_shape)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mposmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg_gt\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbool\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mposmask\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m                 \u001b[0mposdis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m                 \u001b[0mfg_dtm\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mposdis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/ndimage/morphology.py\u001b[0m in \u001b[0;36mdistance_transform_edt\u001b[0;34m(input, sampling, return_distances, return_indices, distances, indices)\u001b[0m\n\u001b[1;32m   2196\u001b[0m         \u001b[0mft\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2198\u001b[0;31m     \u001b[0m_nd_image\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meuclidean_feature_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msampling\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mft\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2199\u001b[0m     \u001b[0;31m# if requested, calculate the distance transform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2200\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_distances\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9aPgIda6xomj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2ac7b36-7c5d-41ab-88ca-885ad45b42f3"
      },
      "source": [
        "value"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5440]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cUrZRbPzmOt"
      },
      "source": [
        "len(val_epoch_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHt15ke0a5TC"
      },
      "source": [
        "a = np.array(time_list_epoch)\n",
        "delta_time_epoch = np.diff(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JTWFhRDSbi7q"
      },
      "source": [
        "b = np.array(time_list_batch)\n",
        "delta_time_step = np.diff(b)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIv-ntjsb14i"
      },
      "source": [
        "avg_step_time = np.mean(delta_time_step)\n",
        "avg_step_time # should be about ~2 seconds per step"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qs07fEvKb91V"
      },
      "source": [
        "avg_epoch_time = np.mean(delta_time_epoch)\n",
        "avg_epoch_time # should be about ~20 seconds per epoch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y18-cBHGlowH"
      },
      "source": [
        "plt.figure(\"Train\", (40, 20))\n",
        "plt.subplot(1, 8, 1)\n",
        "plt.imshow(label_batch[0,0,...,30])\n",
        "plt.subplot(1, 8, 2)\n",
        "plt.imshow(label_batch[0,0,...,35])\n",
        "plt.subplot(1, 8, 3)\n",
        "plt.imshow(label_batch[0,0,...,40])\n",
        "plt.subplot(1, 8, 4)\n",
        "plt.imshow(label_batch[0,0,...,45])\n",
        "plt.subplot(1, 8, 5)\n",
        "plt.imshow(label_batch[0,0,...,50])\n",
        "plt.subplot(1, 8, 6)\n",
        "plt.imshow(label_batch[0,0,...,55])\n",
        "plt.subplot(1, 8, 7)\n",
        "plt.imshow(label_batch[0,0,...,60])\n",
        "plt.subplot(1, 8, 8)\n",
        "plt.imshow(label_batch[0,0,...,65])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PidBN2kfcL70"
      },
      "source": [
        "plt.imshow(val_outputs.detach().numpy()[0,1,...,40])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IP99erNTdWU6"
      },
      "source": [
        "plt.imshow(y_pred[0,1,...,30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QN2s-4VidCmQ"
      },
      "source": [
        "plt.imshow(label_batch[0,0,...,30])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FUmVyUL_c2U6"
      },
      "source": [
        "plt.figure(\"train\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Epoch Average Loss\")\n",
        "x = [i + 1 for i in range(len(epoch_loss_values))]\n",
        "y = epoch_loss_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.title(\"Val Mean Dice\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
        "y = metric_values\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3nt1HB8LNkW"
      },
      "source": [
        "plt.figure(\"Validation\", (12, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.title(\"Validation Loss\")\n",
        "x = [val_interval * (i + 1) for i in range(len(metric_values))]\n",
        "y = val_epoch_loss\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTVWS0tsacQO"
      },
      "source": [
        "plt.figure(\"Time\", (30, 6))\n",
        "plt.title(\"Time per epoch\")\n",
        "x = [i + 1 for i in range(len(a)-1)]\n",
        "y = [a[i+1]-a[i] for i in range(len(a)-1)]\n",
        "plt.xlabel(\"epoch\")\n",
        "plt.plot(x, y)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wQyoeJaj3cW"
      },
      "source": [
        "plt.figure(\"Time\", (30, 6))\n",
        "plt.title(\"Val Mean Dice\")\n",
        "x = [i + 1 for i in range(len(b)-1)]\n",
        "y = [b[i+1]-b[i] for i in range(len(b)-1)]\n",
        "plt.xlabel(\"batch\")\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gx9-qHklcG6"
      },
      "source": [
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    for i, val_data in enumerate(val_loader):\n",
        "        roi_size = (96, 96, 96)\n",
        "        sw_batch_size = 4\n",
        "        val_outputs = sliding_window_inference(\n",
        "            val_data[\"image\"].to(device), (roi_size), sw_batch_size, net\n",
        "        )\n",
        "        # plot the slice [:, :, 80]\n",
        "        plt.figure(\"check\", (18, 6))\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.title(f\"image {i}\")\n",
        "        plt.imshow(val_data[\"image\"][0, 0, :, :, 70])\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.title(f\"label {i}\")\n",
        "        plt.imshow(val_data[\"label\"][0, 0, :, :, 70])\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.title(f\"output {i}\")\n",
        "        plt.imshow(post_pred(val_outputs).detach().cpu()[0,1,..., 70])\n",
        "        plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4exeZtTlcRt"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VFExiYBNlcUl"
      },
      "source": [
        "a = np.ones((5,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hOkWK9ywk5bD"
      },
      "source": [
        "b = np.diff(a)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MVJa1qEk5fr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptdN9CUdk5h9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}